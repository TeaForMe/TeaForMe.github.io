



# Python

## python的单例模式

**单例模式（Singleton Pattern）**是一种常用的软件设计模式，该模式的主要目的是确保**某一个类只有一个实例存在**。当你希望在整个系统中，某个类只能出现一个实例时，单例对象就能派上用场。

比如，某个服务器程序的配置信息存放在一个文件中，客户端通过一个 AppConfig 的类来读取配置文件的信息。如果在程序运行期间，有很多地方都需要使用配置文件的内容，也就是说，很多地方都需要创建 AppConfig 对象的实例，这就导致系统中存在多个 AppConfig 的实例对象，而这样会严重浪费内存资源，尤其是在配置文件内容很多的情况下。事实上，类似 AppConfig 这样的类，我们希望在程序运行期间只存在一个实例对象。。

在 Python 中，我们可以用多种方法来实现单例模式

### 1、使用模块

新建py文件，使用时用import导入，即为单例模式

### 2、使用装饰器

### 3、使用类

```python
class Singleton(object):
    def __init__(self):
        pass

    @classmethod
    def instance(cls, *args, **kwargs):
        if not hasattr(Singleton, "_instance"):
            Singleton._instance = Singleton(*args, **kwargs)
        return Singleton._instance
```
但是这样子做在多线程工作的时候，会有线程不安全的问题，解决方法是加锁！未加锁部分并发执行,加锁部分串行执行,速度降低,但是保证了数据安全

```python
import time
import threading
class Singleton(object):
    _instance_lock = threading.Lock()
    def __init__(self):
        time.sleep(1)

    @classmethod
    @classmethod
    def instance(cls, *args, **kwargs):
        if not hasattr(Singleton, "_instance"):
            with Singleton._instance_lock:
                if not hasattr(Singleton, "_instance"):
                    Singleton._instance = Singleton(*args, **kwargs)
        return Singleton._instance
def task(arg):
    obj = Singleton.instance()
    print(obj)
for i in range(10):
    t = threading.Thread(target=task,args=[i,])
    t.start()
time.sleep(20)
obj = Singleton.instance()
print(obj)    
```


这种方式实现的单例模式，使用时会有限制，以后实例化必须通过 obj = Singleton.instance()

### 4、重写 ____new____方法

```python
import threading
class Singleton(object):
    _instance_lock = threading.Lock()

    def __init__(self):
        pass

    def __new__(cls, *args, **kwargs):
        if not hasattr(Singleton, "_instance"):
            with Singleton._instance_lock:
                if not hasattr(Singleton, "_instance"):
                    Singleton._instance = object.__new__(cls)  
        return Singleton._instance

obj1 = Singleton()
obj2 = Singleton()
print(obj1,obj2)

def task(arg):
    obj = Singleton()
    print(obj)

for i in range(10):
    t = threading.Thread(target=task,args=[i,])
    t.start()
```

## python实现快排

```python
def quick_sort(arr):
    if len(arr) <= 1:
        return arr
    else:
        base = arr[0]
        less = [v for v in arr[1:] if v<=base]
        more = [v for v in arr[1:] if v>base]
        return quick_sort(less) + [base] + quick_sort(more)
```

## Python闭包与装饰器

### 什么是闭包

```python
#定义一个函数
def test(number):
    #在函数内部在定义一个函数，并且这个函数用到了外边函数的变量，那么将这个函数称为闭包
    def test_in(number_in):
        print("in test_in 函数，number_in is %d"%number_in)
        return number+number_in
    return test_in

#给test函数赋值，这个10就是给参数number    
ret=test(10)

#注意这里的100其实给参数number_in
print(ret(100))

#注意这里的200其实给参数number_in
print(ret(200))
```

运行结果：

```python
in test_in函数，number_in is 100
110
in test_in函数，number_in is 200
210
```

### 实现一个装饰器

```python
def debug3(func):
    def wrapper(*args,**kwargs):
        print("[debug]:enter {} ()".format(func))
        print('Prepare and say...')
        return func(*args,**kwargs)
    return wrapper


@debug3
def say(something):
    print('hello{}'.format(something))
```

## python多版本管理

pipenv是requests 作者 Kenneth Reitz大神写的一个python虚拟环境管理工具, 结合了pip和virtualenv的功能, 侧重点还是在包环境管理上, 使用思路是先创建一个指定python版本的环境, 然后在此环境上安装相应的包, 好评不错, 看到很多大牛都在推荐.

virtualenv是一个比较传统成熟的虚拟环境管理工具了, 用的人也比较多, 思路也是创建虚拟环境, 然后安装相应的包, 要进入环境就source一下activate脚本激活一下, 尽管成熟, 但是我个人不太喜欢用, 在部署项目的时候老是容易出现一些环境问题.

pyenv相对来说知名度就差很多了, 不过也很稳定, 这三个环境管理工具我都用过, 我个人更喜欢pyenv, 理由如下:

- 相对于其他两个工具, pyenv更侧重在python 解释器版本管理上, 比包管理更大一个层级, 使用pyenv我可以方便的下载指定版本的python解释器, pypy, anaconda等, 可以随时自由的在shell环境中本地、全局切换python解释器
- 开发的时候不需要限定某个版本的虚拟环境, 只需要在部署的时候用pyenv指定某个版本就好了
- pyenv切换解释器版本的时候, pip和ipython以及对应的包环境都是一起切换的, 所以如果你要同时运行ipython2.x和ipython3.x多个解释器验证一些代码时就很方便
- pyenv也可以创建好指定的虚拟环境, 但不需要指定具体目录, 自由度更高, 使用也简单

## Python生成器和迭代器

### 迭代器

迭代是Python最强大的功能之一，是访问集合元素的一种方式。

迭代器是一个可以记住遍历的位置的对象。

迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。

迭代器有两个基本的方法：**iter()** 创建 和 **next()** 获取下一个。

### 创建一个迭代器

把一个类作为一个迭代器使用需要在类中实现两个方法 __iter__() 与  __next__() 。

类都有一个构造函数，Python 的构造函数为 __init__(), 它会在对象初始化的时候执行。

__iter__() 方法返回一个特殊的迭代器对象， 这个迭代器对象实现了 __next__() 方法并通过 StopIteration 异常标识迭代的完成。

__next__() 方法（Python 2 里是 next()）会返回下一个迭代器对象。

### StopIteration

StopIteration 异常用于标识迭代的完成，防止出现无限循环的情况，在 __next__() 方法中我们可以设置在完成指定循环次数后触发 StopIteration 异常来结束迭代。

### 生成器

在 Python 中，使用了 yield 的函数被称为生成器（generator）。

跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。

在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。

调用一个生成器函数，返回的是一个迭代器对象。


## Python多线程、多进程、携程

从计算机硬件角度：
计算机的核心是CPU，承担了所有的计算任务。
一个CPU，在一个时间切片里只能运行一个程序。

从操作系统的角度：
进程和线程，都是一种CPU的执行单元。
进程：表示一个程序的上下文执行活动（打开、执行、保存...）
线程：进程执行程序时候的最小调度单位（执行a，执行b...)
一个程序至少有一个进程，一个进程至少有一个线程。

并行 和 并发：
并行：多个CPU核心，不同的程序就分配给不同的CPU来运行。可以让多个程序同时执行。
cpu1 -------------
cpu2 -------------
cpu3 -------------
cpu4 -------------

并发：单个CPU核心，在一个时间切片里一次只能运行一个程序，如果需要运行多个程序，则串行执行。
cpu1　　----　　----
cpu1 　　　----　　----

多进程/多线程：
表示可以同时执行多个任务，进程和线程的调度是由操作系统自动完成。
进程：每个进程都有自己独立的内存空间，不同进程之间的内存空间不共享。
进程之间的通信有操作系统传递，导致通讯效率低，切换开销大。
线程：一个进程可以有多个线程，所有线程共享进程的内存空间，通讯效率高，切换开销小。
共享意味着竞争，导致数据不安全，为了保护内存空间的数据安全，引入"互斥锁"。
一个线程在访问内存空间的时候，其他线程不允许访问，必须等待之前的线程访问结束，才能使用这个内存空间。
互斥锁：一种安全有序的让多个线程访问内存空间的机制。

### Python的多线程：
GIL 全局解释器锁：线程的执行权限，在Python的进程里只有一个GIL。
一个线程需要执行任务，必须获取GIL。
好处：直接杜绝了多个线程访问内存空间的安全问题。
坏处：Python的多线程不是真正多线程，不能充分利用多核CPU的资源。
但是，在I/O阻塞的时候，解释器会释放GIL。

所以：

### 多进程：

密集CPU任务，需要充分使用多核CPU资源（服务器，大量的并行计算）的时候，用多进程。 multiprocessing
缺陷：多个进程之间通信成本高，切换开销大。

### 多线程：

密集I/O任务（网络I/O，磁盘I/O，数据库I/O）使用多线程合适。
threading.Thread、multiprocessing.dummy
缺陷：同一个时间切片只能运行一个线程，不能做到高并行，但是可以做到高并发。

### 协程：

又称微线程，在单线程上执行多个任务，用函数切换，开销极小。不通过操作系统调度，没有进程、线程的切换开销。genvent，monkey.patchall
多线程请求返回是无序的，那个线程有数据返回就处理那个线程，而协程返回的数据是有序的。
缺陷：单线程执行，处理密集CPU和本地磁盘IO的时候，性能较低。处理网络I/O性能还是比较高.

 下面以这个网站为例，采用三种方式爬取。爬取前250名的电影。。

https://movie.douban.com/top250?start=0

通过分析网页发现第2页的url start=25，第3页的url start=50,第3页的start=75。因此可以得出这个网站每一页的数局是通过递增start这个参数获取的。

一般不看第一页的数据，第一页的没有参考价值。

![img](https://img2018.cnblogs.com/blog/1259548/201904/1259548-20190403111015923-1074272156.png)

 

这次我们主要爬取，电影名字跟评分。只是使用不同方式去对比下不同点，所以数据方面就不过多提取或者保存。只是简单的将其爬取下打印出来看看。

第一：采用多进程 , multiprocessing 模块。 当然这个耗时更网络好坏有关。在全部要请求都正常的情况下耗时15s多。

1、多进程

```python
#!/usr/bin/env python2
# -*- coding=utf-8 -*-

from multiprocessing import Process, Queue

import time
from lxml import etree
import requests


class DouBanSpider(Process):
    def __init__(self, url, q):
        # 重写写父类的__init__方法
        super(DouBanSpider, self).__init__()
        self.url = url
        self.q = q
        self.headers = {
            'Host': 'movie.douban.com',
            'Referer': 'https://movie.douban.com/top250?start=225&filter=',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.104 Safari/537.36',
        }

    def run(self):
        self.parse_page()

    def send_request(self,url):
        '''
        用来发送请求的方法
        :return: 返回网页源码
        '''
        # 请求出错时，重复请求３次,
        i = 0
        while i <= 3:
            try:
                print u"[INFO]请求url:"+url
                return requests.get(url=url,headers=self.headers).content
            except Exception as e:
                print u'[INFO] %s%s'% (e,url)
                i += 1

    def parse_page(self):
        '''
        解析网站源码，并采用ｘｐａｔｈ提取　电影名称和平分放到队列中
        :return:
        '''
        response = self.send_request(self.url)
        html = etree.HTML(response)
        #　获取到一页的电影数据
        node_list = html.xpath("//div[@class='info']")
        for move in node_list:
            # 电影名称
            title = move.xpath('.//a/span/text()')[0]
            # 评分
            score = move.xpath('.//div[@class="bd"]//span[@class="rating_num"]/text()')[0]
           
            # 将每一部电影的名称跟评分加入到队列
            self.q.put(score + "\t" + title)


def main():
    # 创建一个队列用来保存进程获取到的数据
    q = Queue()
    base_url = 'https://movie.douban.com/top250?start='
    # 构造所有ｕｒｌ
    url_list = [base_url+str(num) for num in range(0,225+1,25)]

    # 保存进程
    Process_list = []
    # 创建并启动进程
    for url in url_list:
        p = DouBanSpider(url,q)
        p.start()
        Process_list.append(p)
    
    # 让主进程等待子进程执行完成
    for i in Process_list:
        i.join()

    while not q.empty():
        print q.get()

if __name__=="__main__":
    
    start = time.time()
    main()
    print '[info]耗时：%s'%(time.time()-start)
```

2、多线程

```python
#!/usr/bin/env python2
# -*- coding=utf-8 -*-
 
from threading import Thread
from Queue import Queue
import time
from lxml import etree
import requests
 
 
class DouBanSpider(Thread):
    def __init__(self, url, q):
        # 重写写父类的__init__方法
        super(DouBanSpider, self).__init__()
        self.url = url
        self.q = q
        self.headers = {
            'Cookie': 'll="118282"; bid=ctyiEarSLfw; ps=y; __yadk_uid=0Sr85yZ9d4bEeLKhv4w3695OFOPoedzC; dbcl2="155150959:OEu4dds1G1o"; as="https://sec.douban.com/b?r=https%3A%2F%2Fbook.douban.com%2F"; ck=fTrQ; _pk_id.100001.4cf6=c86baf05e448fb8d.1506160776.3.1507290432.1507283501.; _pk_ses.100001.4cf6=*; __utma=30149280.1633528206.1506160772.1507283346.1507290433.3; __utmb=30149280.0.10.1507290433; __utmc=30149280; __utmz=30149280.1506160772.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); __utma=223695111.1475767059.1506160772.1507283346.1507290433.3; __utmb=223695111.0.10.1507290433; __utmc=223695111; __utmz=223695111.1506160772.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); push_noty_num=0; push_doumail_num=0',
            'Host': 'movie.douban.com',
            'Referer': 'https://movie.douban.com/top250?start=225&filter=',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.104 Safari/537.36',
        }
 
    def run(self):
        self.parse_page()
 
    def send_request(self,url):
        '''
        用来发送请求的方法
        :return: 返回网页源码
        '''
        # 请求出错时，重复请求３次,
        i = 0
        while i <= 3:
            try:
                print u"[INFO]请求url:"+url
                html = requests.get(url=url,headers=self.headers).content
            except Exception as e:
                print u'[INFO] %s%s'% (e,url)
                i += 1
            else:
                return html
 
    def parse_page(self):
        '''
        解析网站源码，并采用ｘｐａｔｈ提取　电影名称和平分放到队列中
        :return:
        '''
        response = self.send_request(self.url)
        html = etree.HTML(response)
        #　获取到一页的电影数据
        node_list = html.xpath("//div[@class='info']")
        for move in node_list:
            # 电影名称
            title = move.xpath('.//a/span/text()')[0]
            # 评分
            score = move.xpath('.//div[@class="bd"]//span[@class="rating_num"]/text()')[0]
 
            # 将每一部电影的名称跟评分加入到队列
            self.q.put(score + "\t" + title)
 
 
def main():
    # 创建一个队列用来保存进程获取到的数据
    q = Queue()
    base_url = 'https://movie.douban.com/top250?start='
    # 构造所有ｕｒｌ
    url_list = [base_url+str(num) for num in range(0,225+1,25)]
 
    # 保存线程
    Thread_list = []
    # 创建并启动线程
    for url in url_list:
        p = DouBanSpider(url,q)
        p.start()
        Thread_list.append(p)
 
    # 让主线程等待子线程执行完成
    for i in Thread_list:
        i.join()
 
    while not q.empty():
        print q.get()
 
if __name__=="__main__":
 
    start = time.time()
    main()
    print '[info]耗时：%s'%(time.time()-start)
```

3、携程

```python
#!/usr/bin/env python2
# -*- coding=utf-8 -*-

from Queue import Queue
import time
from lxml import etree
import requests
import gevent

#　打上猴子补丁
from gevent import monkey
monkey.patch_all()

class DouBanSpider(object):
    def __init__(self):
        # 创建一个队列用来保存进程获取到的数据
        self.q = Queue()
        self.headers = {
            'Cookie': 'll="118282"; bid=ctyiEarSLfw; ps=y; __yadk_uid=0Sr85yZ9d4bEeLKhv4w3695OFOPoedzC; dbcl2="155150959:OEu4dds1G1o"; as="https://sec.douban.com/b?r=https%3A%2F%2Fbook.douban.com%2F"; ck=fTrQ; _pk_id.100001.4cf6=c86baf05e448fb8d.1506160776.3.1507290432.1507283501.; _pk_ses.100001.4cf6=*; __utma=30149280.1633528206.1506160772.1507283346.1507290433.3; __utmb=30149280.0.10.1507290433; __utmc=30149280; __utmz=30149280.1506160772.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); __utma=223695111.1475767059.1506160772.1507283346.1507290433.3; __utmb=223695111.0.10.1507290433; __utmc=223695111; __utmz=223695111.1506160772.1.1.utmcsr=(direct)|utmccn=(direct)|utmcmd=(none); push_noty_num=0; push_doumail_num=0',
            'Host': 'movie.douban.com',
            'Referer': 'https://movie.douban.com/top250?start=225&filter=',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/59.0.3071.104 Safari/537.36',
        }

    def run(self,url):
        self.parse_page(url)

    def send_request(self,url):
        '''
        用来发送请求的方法
        :return: 返回网页源码
        '''
        # 请求出错时，重复请求３次,
        i = 0
        while i <= 3:
            try:
                print u"[INFO]请求url:"+url
                html = requests.get(url=url,headers=self.headers).content
            except Exception as e:
                print u'[INFO] %s%s'% (e,url)
                i += 1
            else:
                return html

    def parse_page(self,url):
        '''
        解析网站源码，并采用ｘｐａｔｈ提取　电影名称和平分放到队列中
        :return:
        '''
        response = self.send_request(url)
        html = etree.HTML(response)
        #　获取到一页的电影数据
        node_list = html.xpath("//div[@class='info']")
        for move in node_list:
            # 电影名称
            title = move.xpath('.//a/span/text()')[0]
            # 评分
            score = move.xpath('.//div[@class="bd"]//span[@class="rating_num"]/text()')[0]

            # 将每一部电影的名称跟评分加入到队列
            self.q.put(score + "\t" + title)


    def main(self):


        base_url = 'https://movie.douban.com/top250?start='
        # 构造所有ｕｒｌ
        url_list = [base_url+str(num) for num in range(0,225+1,25)]
        # 创建协程并执行
        job_list = [gevent.spawn(self.run,url) for url in url_list]
        # 让线程等待所有任务完成，再继续执行。
        gevent.joinall(job_list)

        while not self.q.empty():
            print self.q.get()

if __name__=="__main__":
    start = time.time()
    douban = DouBanSpider()
    douban.main()
    print '[info]耗时：%s'%(time.time()-start)
```

## Python垃圾回收机制

### 一.垃圾回收机制

Python中的垃圾回收是以引用计数为主，分代收集为辅。引用计数的缺陷是循环引用的问题。
在Python中，如果一个对象的引用数为0，Python虚拟机就会回收这个对象的内存。

```python
#encoding=utf-8
__author__ = 'kevinlu1010@qq.com'

class ClassA():
    def __init__(self):
        print 'object born,id:%s'%str(hex(id(self)))
    def __del__(self):
        print 'object del,id:%s'%str(hex(id(self)))

def f1():
    while True:
        c1=ClassA()
        del c1
```

执行f1()会循环输出这样的结果，而且进程占用的内存基本不会变动

```python
object born,id:0x237cf58
object del,id:0x237cf58
```

`c1=ClassA()`会创建一个对象，放在`0x237cf58`内存中，c1变量指向这个内存，这时候这个内存的引用计数是1
`del c1`后，c1变量不再指向`0x237cf58`内存，所以这块内存的引用计数减一，等于0，所以就销毁了这个对象，然后释放内存。

1. #### 导致引用计数+1的情况

   1. 对象被创建，例如`a=23`
   2. 对象被引用，例如`b=a`
   3. 对象被作为参数，传入到一个函数中，例如`func(a)`
   4. 对象作为一个元素，存储在容器中，例如`list1=[a,a]`

2. #### 导致引用计数-1的情况

   1. 对象的别名被显式销毁，例如`del a`
   2. 对象的别名被赋予新的对象，例如`a=24`
   3. 一个对象离开它的作用域，例如f函数执行完毕时，func函数中的局部变量（全局变量不会）
   4. 对象所在的容器被销毁，或从容器中删除对象

   demo

   ```python
    def func(c,d):
        print 'in func function', sys.getrefcount(c) - 1
   
   
    print 'init', sys.getrefcount(11) - 1
    a = 11
    print 'after a=11', sys.getrefcount(11) - 1
    b = a
    print 'after b=1', sys.getrefcount(11) - 1
    func(11)
    print 'after func(a)', sys.getrefcount(11) - 1
    list1 = [a, 12, 14]
    print 'after list1=[a,12,14]', sys.getrefcount(11) - 1
    a=12
    print 'after a=12', sys.getrefcount(11) - 1
    del a
    print 'after del a', sys.getrefcount(11) - 1
    del b
    print 'after del b', sys.getrefcount(11) - 1
    # list1.pop(0)
    # print 'after pop list1',sys.getrefcount(11)-1
    del list1
    print 'after del list1', sys.getrefcount(11) - 1
   ```

   输出：

   ```python
    init 24
    after a=11 25
    after b=1 26
    in func function 28
    after func(a) 26
    after list1=[a,12,14] 27
    after a=12 26
    after del a 26
    after del b 25
    after del list1 24
   ```

   **问题：为什么调用函数会令引用计数+2**

3. #### 查看一个对象的引用计数

`sys.getrefcount(a)`可以查看a对象的引用计数，但是比正常计数大1，因为调用函数的时候传入a，这会让a的引用计数+1

### 二.循环引用导致内存泄露

```python
def f2():
    while True:
        c1=ClassA()
        c2=ClassA()
        c1.t=c2
        c2.t=c1
        del c1
        del c2
        
```

执行f2()，进程占用的内存会不断增大。

```python
object born,id:0x237cf30
object born,id:0x237cf58
```

创建了c1，c2后，`0x237cf30`（c1对应的内存，记为内存1）,`0x237cf58`（c2对应的内存，记为内存2）这两块内存的引用计数都是1，执行`c1.t=c2`和`c2.t=c1`后，这两块内存的引用计数变成2.
在del c1后，内存1的对象的引用计数变为1，由于不是为0，所以内存1的对象不会被销毁，所以内存2的对象的引用数依然是2，在del c2后，同理，内存1的对象，内存2的对象的引用数都是1。
虽然它们两个的对象都是可以被销毁的，但是由于**循环引用**，导致垃圾回收器都不会回收它们，所以就会导致内存泄露。

### 三.垃圾回收

```python
deff3():
    # print gc.collect()
    c1=ClassA()
    c2=ClassA()
    c1.t=c2
    c2.t=c1
    del c1
    del c2
    print gc.garbage
    print gc.collect() #显式执行垃圾回收
    print gc.garbage
    time.sleep(10)
if __name__ == '__main__':
    gc.set_debug(gc.DEBUG_LEAK) #设置gc模块的日志
    f3()
```

输出：

```python
gc: uncollectable <ClassA instance at 0230E918>
gc: uncollectable <ClassA instance at 0230E940>
gc: uncollectable <dict 0230B810>
gc: uncollectable <dict 02301ED0>
object born,id:0x230e918
object born,id:0x230e940
4
```

- 垃圾回收后的对象会放在gc.garbage列表里面
- `gc.collect()`会返回**不可达**的对象数目，4等于两个对象以及它们对应的dict
- 有三种情况会触发垃圾回收：
  1.调用`gc.collect()`,
  2.当gc模块的计数器达到阀值的时候。
  3.程序退出的时候

### 四.gc模块常用功能解析

[Garbage Collector interface](https://docs.python.org/2/library/gc.html)
gc模块提供一个接口给开发者设置垃圾回收的选项。上面说到，采用引用计数的方法管理内存的一个缺陷是循环引用，而gc模块的一个主要功能就是解决循环引用的问题。

#### 常用函数：

1. gc.set_debug(flags)
   设置gc的debug日志，一般设置为gc.DEBUG_LEAK
2. gc.collect([generation])
   显式进行垃圾回收，可以输入参数，0代表只检查第一代的对象，1代表检查一，二代的对象，2代表检查一，二，三代的对象，如果不传参数，执行一个full collection，也就是等于传2。
   返回不可达（unreachable objects）对象的数目
3. gc.set_threshold(threshold0[, threshold1[, threshold2])
   设置自动执行垃圾回收的频率。
4. gc.get_count()
   获取当前自动执行垃圾回收的计数器，返回一个长度为3的列表
5. 

#### gc模块的自动垃圾回收机制

必须要import gc模块，并且is_enable()=True才会启动自动垃圾回收。
这个机制的主要作用就是发现并处理不可达的垃圾对象。
垃圾回收=垃圾检查+垃圾回收
在Python中，采用分代收集的方法。把对象分为三代，一开始，对象在创建的时候，放在一代中，如果在一次一代的垃圾检查中，改对象存活下来，就会被放到二代中，同理在一次二代的垃圾检查中，该对象存活下来，就会被放到三代中。

gc模块里面会有一个长度为3的列表的计数器，可以通过`gc.get_count()`获取。
例如`(488,3,0)`，其中`488`是指距离上一次一代垃圾检查，Python分配内存的数目减去释放内存的数目，**注意是内存分配，而不是引用计数的增加**。例如：

```python
print gc.get_count()  # (590, 8, 0)
a = ClassA()
print gc.get_count()  # (591, 8, 0)
del a
print gc.get_count()  # (590, 8, 0)
```

`3`是指距离上一次二代垃圾检查，一代垃圾检查的次数，同理，`0`是指距离上一次三代垃圾检查，二代垃圾检查的次数。

gc模快有一个自动垃圾回收的阀值，即通过`gc.get_threshold`函数获取到的长度为3的元组，例如`(700,10,10)`
每一次计数器的增加，gc模块就会检查增加后的计数是否达到阀值的数目，如果是，就会执行对应的代数的垃圾检查，然后重置计数器
例如，假设阀值是`(700,10,10)`：

- 当计数器从`(699,3,0)`增加到`(700,3,0)`，gc模块就会执行`gc.collect(0)`,即检查一代对象的垃圾，并重置计数器为`(0,4,0)`
- 当计数器从`(699,9,0)`增加到`(700,9,0)`，gc模块就会执行`gc.collect(1)`,即检查一、二代对象的垃圾，并重置计数器为`(0,0,1)`
- 当计数器从`(699,9,9)`增加到`(700,9,9)`，gc模块就会执行`gc.collect(2)`,即检查一、二、三代对象的垃圾，并重置计数器为`(0,0,0)`

#### 其他

1. 如果循环引用中，两个对象都定义了`__del__`方法，gc模块不会销毁这些不可达对象，因为gc模块不知道应该先调用哪个对象的`__del__`方法，所以为了安全起见，gc模块会把对象放到gc.garbage中，但是不会销毁对象。

### 五.应用

1. 项目中避免循环引用
2. 引入gc模块，启动gc模块的自动清理循环引用的对象机制
3. 由于分代收集，所以把需要长期使用的变量集中管理，并尽快移到二代以后，减少GC检查时的消耗
4. gc模块唯一处理不了的是循环引用的类都有`__del__`方法，所以项目中要避免定义_`_del__`方法，如果一定要使用该方法，同时导致了循环引用，需要代码显式调用`gc.garbage`里面的对象的`__del__`来打破僵局

## Python列表元组问题

### 修改问题 

原则上列表可修改，元组不可修改。但是元组套列表（[]），可以修改对应的列表；列表套元组[（）]，不可修改里面的元组。

tuple元组的不可变是指元素对象的引用不可变，不能对其再次赋值，但是在其中可变元素对象的引用不被修改前提下，仍旧可以对可变元素对象修改

### 列表倒序

***list.sort(self, key=None, reverse=True)***

***list.reverse()***

***list[::-1]***

## Python拷贝问题

- **直接赋值：**其实就是对象的引用（别名）。

- **浅拷贝(copy)：**拷贝父对象，不会拷贝对象的内部的子对象。

- **深拷贝(deepcopy)：** copy 模块的 deepcopy 方法，完全拷贝了父对象及其子对象。

- 1、**b = a:** 赋值引用，a 和 b 都指向同一个对象。

  ![img](https://www.runoob.com/wp-content/uploads/2017/03/1489720931-7116-4AQC6.png)

  **2、b = a.copy():** 浅拷贝, a 和 b 是一个独立的对象，但他们的子对象还是指向统一对象（是引用）。

  ![img](https://www.runoob.com/wp-content/uploads/2017/03/1489720930-6827-Vtk4m.png)

  **b = copy.deepcopy(a):** 深度拷贝, a 和 b 完全拷贝了父对象及其子对象，两者是完全独立的。

  ![img](https://www.runoob.com/wp-content/uploads/2017/03/1489720930-5882-BO4qO.png)



# TCP建立连接和释放连接过程

TCP（Transmission Control Protocol [传输控制协议](https://baike.baidu.com/item/传输控制协议)）是一种面向连接的、可靠的、基于字节流的[传输层](https://baike.baidu.com/item/传输层)通信协议。TCP建立连接需要三次握手，释放连接需要四次握手。

## TCP整个过程流程图

![img](https://images2018.cnblogs.com/blog/1158196/201803/1158196-20180301190534920-1824529844.png)

并且TCP整个过程可以看成是状态机

 ![img](https://images2018.cnblogs.com/blog/1158196/201803/1158196-20180301191336765-262732211.png)

 

## TCP建立过程（三次握手）

![img](https://images2018.cnblogs.com/blog/1158196/201803/1158196-20180301191116528-1173543278.png)

 TCP连接过程：

（1） 服务端通过socket，bind和listen准备好接受外来的连接，此时服务端状态为Listen

（2）客户端通过调用connect来发起主动连接，导致客户端TCP发送一个SYN（同步）字节，告诉服务器客户将在（待建立的）连接中发送的数据的初始序列号，客户端状态为SYN_SENT。

（3）服务器确认（ACK）客户的SYN，并自己也发送一个SYN，它包含服务器将在同一连接中发送数据的初始序列号。

（4）客户端确认服务的ACK和SYN，向服务器发送ACK，客户端状态ESTABLISHED

（5）服务器接收ACK,服务器状态ESABLISHED。

## TCP关闭过程（四次挥手）

![img](https://images2018.cnblogs.com/blog/1158196/201803/1158196-20180301191028587-1027330495.png)

 TCP连接中止过程：

（1）某端首先调用close，成为主动关闭端，向另一端发送FIN分节，表示数据发送完毕，此时主动关闭端状态FIN_WAIT_1；

（2）接收到FIN的是被动关闭端，FIN由TCP确认，先向主动关闭端发送ACK，作为一个文件结束符传递给接收端应用进程（放在已排队等候该应用进程接收到的任何其他数据之后），因为FIN的接收意味着接收端应用进程在相应连接无额外数据可接收，接收端状态CLOSE_WAIT；主动关闭端接收到ACK状态变为FIN_WAIT_2；

（3）一段时间后，接收端接收到这个文件结束符的应用进程调用close关闭套接字，向主动关闭端发送FIN，接收端状态为LAST_ACK；

（4）主动关闭端确认FIN，状态变为TIME_WAIT，并向接收端发送ACK，接收端接收到ACK关闭TCP，而主动关闭端一段时间后也关闭TCP；



